\chapter{State of the Art}
\label{chap:state_of_the_art}

\begin{chapterintro}

In this chapter, a brief introduction of the state of the art for conversational agents and Question Answering is presented. Likewise, we will take a short look at some Linked Open Data systems, and the ways to recover data for them.


\end{chapterintro}

\cleardoublepage

\section{Overview}


Conversational agents, pressented in section \ref{sec:conv_agents} are systems that allow an user to interact with using natural language, the same way they will interact will another humar being. This is achieved by using engines that analyse the user input, process it, and provide the best possible answer given the knowledge of the system.

Question answering systems work in a similar way, but rather than provide a response in natural language, they present the user the resource where the answer to their question is located, usually by translating the question to a specialised query for a given database.

The aforementioned database is usually a Linked Open Data System. This systems allow the publication of Semantic data, connecting it to the world and making therefore easily accesible and linkable.

Finally, we will study the way of populating the system, using web scrapping techniques in order to recover the information when it is not presented as Linked Open Data.

\section{Conversational Agents}
\label{sec:conv_agents}

In this section we will discuss the evolution of conversational engines, and discuss a few of the techniques and technologies utilized implementing them. We will provide a small overview to \ac{AIML} and some engines implemented with it, as well as other engines to finalise with a small description of ChatScript.

One of the starting points when studying conversational agents is A.L.I.C.E. an free natural language artificial intelligence chat robot that utilizes AIML for creating responses based on the user input to the system. ALICE won the 2000, 2001, and 2004 Loebner prizes, becoming a starting point while developing conversational agents. It makes use of the pattern-matching ability of AIML, with 120.000 patterns that can either trigger a response o redirect the input to another pattern. ALICE was inspired by Eliza, on the first examples of natural language processing using simple patterns, written at MIT by Joseph Weizenbaum between 1964 and 1966.

Along with ALICE, a number of other AIML conversational agents have been presented to the Loebner contest, by different authors, usually getting good results, like Mitsuku, by Steve Worswick, who won the 2013 edition of the contest, and was among the 4 finalists in 2014, three of them using AIML. Another example of an AIML bot is Izar, by Brian Rigsby, who achieved second place in the 2014 contest

The winner of the 2010, 2011 and 2014 contests was Bruce WillCox, using different chatbots, all of them written in ChatScript. Chatscript was presented in 2010, written in C++, and later released as Open Source. Whilst AIML aims to pattern-match words, ChatScript claims to match in a general meaning basis, focusing on detecting equivalence and paying heavy attention to sets of words and canonical representation, and providing a simple way of storing user data, in a machine readable format.

\subsection{\ac{AIML}}

\ac{AIML}~\cite{aimlprimer} is a widely use XML dialect for creating conversational language. It was developed between 1995 and 2002 by Richard S. Wallace and the free software community, and has remained relevant to this date, including the draft for a major upgrade, AIML 2.0, released in the early 2013, and currently being working on. The original version of AIML had seven design goals, stated in its primer:
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item Shall be easy to learn.
  \item Shall encode the miniaml concept set necessary to enable a stimulus-response knowledge system modelled on that of the original A.L.I.C.E.
  \item Shall be compatible with XML.
  \item It shall be easy to write programs that process AIML documents.
  \item \ac{AIML} objects should be human-legible and reasonably clear.
  \item The design of \ac{AIML} shall be formal and concise.
  \item \ac{AIML} shall not incorporate dependencies upon any other language.
\end{enumerate}

There are more than twenty tags for the AIML language~\cite{aliceaiml}, but the most important units are \emph{aiml}, the tag that defines a document as \ac{AIML}, \emph{category} marking a ``unit of knowledge'' in the bot's knowledge base, \emph{pattern} contains a simple pattern that will be compared with the user input, and \emph{template} containing the response to a user input.

\emph{\textcolor{red}{Add example aiml code?}}

The free A.L.I.C.E. \ac{AIML}~\footnote{\url{http://www.alicebot.org/downloads/}} includes a knowledge base of 41.000 categories, and can be used as a base for others bots.

\subsubsection{\ac{AIML} 2.0}

In January 2013 the ALICE A.I. Foundation released a draft specification for a major update for \ac{AIML}~\footnote{\url{http://alicebot.blogspot.com.es/2013/01/aiml-20-draft-specification-released.html}}, aiming to provide new features while trying to keep \ac{AIML} as simple as possible. \ac{AIML} 2.0 combines Pandorabots extensions to the language, \ac{OoB} tags and a collection of new features. The full list of new features can be found in the Working Draft~\cite{aiml20draft}, some of the more relevant are:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item Zero+ wildcards, allowing to match zero or more words
  \item Setting matching priority for certain words.
  \item Loops.
  \item \ac{OoB} tags.
  \item Local variables.
\end{itemize}

\subsubsection{\ac{AIML} implementations}

\ac{AIML} has been implemented in multiple languages, including Java, Python, PHP or C++. Some of those implementations are listed in the ALICE downloads page~\footnote{\url{http://www.alicebot.org/downloads/programs.html}}, and we will briefly describe some of them bellow:

\begin{enumerate}
 \item \textbf{Program D} is a Java implementation, open source, implementing the \ac{AIML} specification. It supports multiple bots per instance, and provides multiple ways to interfaces to interact with the service, providing a J2EE release allowing deployment as a webservice. However, the development of this project has been stagnated for years, with its last release in 2006.
 \item \textbf{ChatterBean} is another Java implementation, aiming to be \ac{AIML} 1.0.1 compliant, using a JavaBeans plugin architecture, and released under a GPL license. However, the last version was released on 2006 and the development since then seems to have stopped.
 \item \textbf{Program O}, written in PHP with MySQL, is an \ac{AIML} engine with a web interface providing a number of remarkable features, including an administration panel, with configuration, teaching an testing interfaces. It stores the \ac{AIML} files in a MySQl database in order to improve its performance, and can assign different personalities to each bot. It is under active development by Ellizabeth Perreau and Dave Morton, with it latest version released in May 2014. 
\end{enumerate}

\subsection{ChatScript}

ChatScript, written in C++ by Bruce Willcox, is a chatbot engine aiming to overcome the limitations of \ac{AIML}, by providing pattern matching on general meaning rather than particular words. It was originally created for Avatar Reality, a start-up company that wanted to create a virtual world called Blue Mars~\cite{Wilcox2010suzzete}, and it was eventually released as open source as per the requirements for the Loebner prize.

Since then, ChatScript has been updating and introducing improvements, up to version 5.4~\cite{ChatScriptSourceForge}. Some of the features in ChatScript include:
\begin{itemize}
 \item Efficient, easily readable output rules
 \item Zero-length wildcards
 \item Concise pattern matching through the use of concepts
 \item Built-in data covering multiple subjects and topics
\end{itemize}

By matching in meaning, ChatScript claims to be able to provide a better user experience than \ac{AIML}, with a much smaller rule set, improving maintainability and ease to modify the bot whenever necessary. More details on ChatScript are provided in section ~\ref{subsec:chatscript}.

\emph{\textcolor{red}{Cortana? Siri/Sirius?}}

\section{Question Answering Systems}
\label{sec:qa_sys}

\ac{QA} is a discipline concerned with automatically provide answers to questions presented in natural language, using a number of different approaches in order to process the question into a query the system can understand, and, therefore, answer.

In general, we can differentiate six major general approaches~\cite{unger2014an}:

\begin{itemize}
  \item \textbf{Controlled natural languages:} The system only takes into account a well-defined subset of a given natural language that can be unambiguously interpreted.
  \item \textbf{Formal grammars processing:} Relaying on linguistics to assign syntactic and semantic representations to lexical units, as well as compositional semantics, this systems compute a representation of the question. Two examples of this systems could be ORAKEL~\cite{cimiano2008towards} and Pythia~\cite{unger2011pythia}
  \item \textbf{Mapping linguistics to semantic structures:} Systems designed under this principle rely on a measure of similarity between elements in the query and the predicates, subjects or objects in the knowledge base. PowerAqua~\cite{lopez2011poweraqua} and Aqualog~\cite{lopez2007aqualog} are two examples of this approach.
  \item \textbf{Template-based:} Taking two stages, this approach first construct a query based on the linguistic analysis of the input question, and the matchs the expressions in the question with elements from the dataset. TBSL~\cite{unger2012template} implements this approach.
  \item \textbf{Graph exploration:} This approach maps elements of the question to entities in the knowledge base, and proceeds navigation from these pivot elements to navigate the graph, seeking to connect the entities to yield a connected query. This example is taken by the TREO~\cite{freitas2011querying} system
  \item \textbf{Machine learning:} question answering has been considered a machine learning problem, with either models for joint query interpretation and response ranking, aiming at learning semantic parsers given a knowledge base and a set of questions and answers, or systems with an algorithm for matching natural language expressions and ontology concepts, as well as an algorithm for storing matches in a parse lexicon.
\end{itemize}

\emph{\textcolor{red}{Shortly describe the exampe systems?}}

To the aforementioned systems, we have to add another one: IBM Watson's DeepQA. Designed to be a contestant in the Jeopardy! quiz show, the DeepQA system had multiple information sources, the DeepQA system focused on extracting and scoring evidence from unstructured data, although it also used structured an semantic data sources. It was build as a massively probabilistic evidence-based architecture using more than 100 different techniques for analysing natural language. \emph{\textcolor{red}{Add figure or list with the structure?}} It was build using Apache UIMA~\footnote{\url{http://uima.apache.org/}}, an Unstructured Information Management system.

\section{Linked Data Systems}
\label{sec:linkd_sys}

Linked Data consists in a set of rules about publishing data in the web so it can be interlinked and accessed using semantic queries. The term was first used by Tim Berners-Lee while talking about the Semantic Web project. Additionally, Linked Open Data is an extension of the Linked Data concept, requiring that the data provided is open content.

\emph{\textcolor{red}{Add the linked data cloud?}}

There are a number of Linked Data Systems publicly available to the public, as long as multiple projects allowing to deploy your own linked data services. Some of them are described in the next sections. 

\subsection{Apache Lucene and Solr}
\label{sec:statesolr}

Not considered Linked Data Systems on its own, Apache Lucene~\footnote{\url{http://lucene.apache.org/}} is a high-performance full-featured text search engine, that can be used as the foundation of many systems. Apache Solr is built on top of Lucene, providing distributed indexing, replication and querying, with multiple features and functionalities~\footnote{\url{http://lucene.apache.org/solr/}}t:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item Full-text search, with powerful matching capabilities, powered by Lucene.
  \item Optimized for High Volume traffic.
  \item Standards Based Open interfaces, including json, xml and http.
  \item Comprehensive Administration Interfaces, making it easy to handle Solr instances.
  \item Easy Monitoring, publishing relevant data via JMX
  \item Highly scalable and Fault tolerant, using Apache ZooKeeper, is easy to scale and distribute the load.
\end{itemize}

Apache Solr is used as a base in many other systems, including some of the described in the following sections.

% Add stanbol here?

\subsection{Linked Media Framework and Apache Marmotta}

Started as the Linked Media Framework~\footnote{\url{https://bitbucket.org/srfgkmt/lmf/}}, this project aimed to provide an easy to setup server to offer linked media management, publishing linked data and allowing interactions with it. \ac{LMF} is built in modules, some of them optional, allowing the extension of the functionalities in the Linked Media Server. Some of the implemented modules are:

\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
  \item \ac{LMF} Semantic Search allowing for a search service on top of Apache Solr. 
  \item \ac{LMF} Stanbol Integration, using Apache Stanbol for content analysis and interlinking.
  \item \ac{LMF} SKOS editor, to manage SKOS thesauruses imported in the Linked Media Server.
\end{itemize}

The core functionalities of \ac{LMF} where set aside to incubate Apache Marmotta, an Open Platform for Linked Data within the Apache Software Foundation~\footnote{\url{http://www.apache.org/}} aiming to provide an implementation for Linked Data that can be used to both publish Linked Data and build custom applications for Linked Data.

% Apache Marmotta / LMF
% DBpedia / virtuoso?
% Apache UIMA ?
% Apache Lucene / Solr / Stanbol ? 
% Terrier ? 


\subsection{Question Answering over Linked Data Systems}
\label{subsec:qa_linked}

\emph{\textcolor{red}{Maybe remove this subsection?}}

